{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c83038ea-f785-4a30-b3e4-0f17380dba56",
   "metadata": {},
   "source": [
    "# LH5, DataGroup, and DSP Optimization Tutorial\n",
    "\n",
    "Clint Wiseman, UW.  Presented at [LEGEND Software Tutorial, Nov. 2021](https://indico.legend-exp.org/event/561/)\n",
    "\n",
    "With Ge and SiPM detectors, we need to be able to **look at waveforms,and quickly find optimal DSP parameters to get the best energy resolution and pulse shape discrimination**.  \n",
    "\n",
    "Users should be able to run this notebook to manually search for \"best guess\" parameters. \n",
    "You can select a group of files to analyze using the `fileDB.h5` and a pandas query for a particular set of files.  This notebook only needs the **raw LH5 files,** and requires the user just manually select the **1460 and 2615** keV peaks, using the onboard energy parameter from the Struck card. \n",
    "\n",
    "Here are a few things we want to do in this notebook:\n",
    "\n",
    "- Show an example of `DataGroup`, which is frequently used for detector test stand setups (CAGE, HADES, SURF, etc.)\n",
    "- Give examples of **creating and reading LH5 files**, which are required by pygama's `ProcessingChain` DSP class.\n",
    "- **Optimize pole-zero corrections** to flatten the waveforms in `[4250:5500], [4250:8000]`\n",
    "- **Optimize energy trapezoid** integration and flat top times (including asymmetric trap) to get best energy resolution\n",
    "- **Optimize DCR parameter** -- vary the windows used to maximize alpha/gamma separation\n",
    "- TODO: Optimize energy with charge trapping correction (see notes at the end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a9c9b6-38c8-4584-b28c-8061280b187f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, h5py, json, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# use this to get interactive plots at NERSC.  \n",
    "# requires ipympl & jupyter-matplotlib extension for jupyterlab\n",
    "# user may need to $pip install ipympl --update\n",
    "%matplotlib widget\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    from tqdm import tqdm\n",
    "    tqdm.pandas() # suppress annoying FutureWarning\n",
    "\n",
    "import pygama.analysis.histograms as pgh\n",
    "import pygama.analysis.peak_fitting as pgf\n",
    "from pygama import DataGroup, lh5\n",
    "from pygama.dsp.dsp_optimize import *\n",
    "from pygama.dsp.WaveformBrowser import WaveformBrowser as wfb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60d0116-816d-4b31-b4aa-03274447913c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# << -- CONFIG -- >> # \n",
    "\n",
    "# set query\n",
    "# query = \"run == 280\" # \"2185-2212\", \"alp\", \"elog 364. overnight alpha run\"\n",
    "query = 'cycle > 2185 and cycle < 2188'\n",
    "\n",
    "# set raw energy estimator\n",
    "etype = 'energy'\n",
    "tb_in = 'ORSIS3302DecoderForEnergy/raw'\n",
    "wf_in = 'ORSIS3302DecoderForEnergy/raw/waveform'\n",
    "xlo, xhi, xpb = 0, 4e6, 10000\n",
    "\n",
    "# set rough calibration: user fills this in from the first plot, below\n",
    "peaks = {\n",
    "    '40K':  [1460.8, 1.71e6],\n",
    "    '208TL':[2614.5, 3.06e6]\n",
    "}\n",
    "\n",
    "# set up a WaveformBrowser for just one of the peaks (user-selected)\n",
    "pk_select = '208TL'\n",
    "# pk_select = '40K'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af72faf8-50a8-479e-b657-4dd4c3d945fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from the raw files.\n",
    "# we need cycle number and packet index information to retrieve waveforms, so make a dataframe\n",
    "\n",
    "dg = DataGroup('./metadata/cage.json', load=True)\n",
    "dg.fileDB.query(query, inplace=True)\n",
    "\n",
    "if len(dg.fileDB)==0:\n",
    "    print('Error, no files found.  Check your query, and fileDB.h5.')\n",
    "    dg.fileDB[['runtype', 'run', 'cycle']]\n",
    "\n",
    "def load_file(row):\n",
    "    data_cols = [etype, 'ievt']\n",
    "    raw_file = dg.lh5_dir + row['raw_path'] + '/' + row['raw_file']\n",
    "    raw_cycle = row.cycle\n",
    "    raw_data = pd.DataFrame(lh5.load_nda(raw_file, data_cols, tb_in, verbose=False))\n",
    "    raw_data['cycle'] = row['cycle']\n",
    "    return raw_data\n",
    "        \n",
    "result = dg.fileDB.progress_apply(load_file, axis=1)\n",
    "df_data = pd.concat([r for r in result])\n",
    "df_mem = round(sys.getsizeof(df_data) / 1024 / 1024, 2)\n",
    "\n",
    "print('Found unique cycles:', df_data['cycle'].unique())\n",
    "print(f\"Entries found: {df_data.shape}\")\n",
    "print('In-memory size:', df_mem, \"MB\")\n",
    "\n",
    "raw_files = dg.lh5_dir + dg.fileDB['raw_path'] + '/' + dg.fileDB['raw_file']\n",
    "\n",
    "with h5py.File(raw_files.iloc[0], 'r') as hf:\n",
    "    print('LH5 columns found :', list(hf[f'{tb_in}'].keys()))\n",
    "    \n",
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0369cbab-05b1-4c4d-8570-4a89e572dabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create raw energy histogram\n",
    "%matplotlib widget\n",
    "hist, bins, var = pgh.get_hist(df_data['energy'], range=(xlo, xhi), dx=xpb)\n",
    "bins = bins[1:] # trim zero bin, not needed with ds='steps'\n",
    "plt.semilogy(bins, hist, ds='steps', c='b', lw=1, label=etype)\n",
    "plt.xlabel(etype)\n",
    "plt.ylabel(f'cts, {xpb}/bin')\n",
    "plt.show()\n",
    "print('Hey, you need to zoom in and pick out the locations of the 1460 and 2615 peaks and write them into the config at the top!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d7dcb9-99f2-4186-ae47-3995a58cc05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "# select events in peaks using a rough FWHM, optimized for onboard energy.\n",
    "# this should work automatically if 'peaks' is correct.\n",
    "# a lot of this is reused from CAGE energy_cal.py :: fit_peaks\n",
    "\n",
    "evts_pass = {}\n",
    "\n",
    "# adjustable parameters for auto-binning\n",
    "win_multip = 30\n",
    "nbin_gain = 4\n",
    "nevt_max = 5000 # num. waveforms to retrieve from each peak\n",
    "nsig_save = 4 # num. sig to save.  may need to be able to re-fit the whole peak\n",
    "\n",
    "fig, axs = plt.subplots(1, len(peaks), figsize=(len(peaks)*5, 4))\n",
    "\n",
    "for ipk, (pk, (cal_e, raw_e)) in enumerate(peaks.items()):\n",
    "    \n",
    "    # set the window.  assume resolution goes as roughly sqrt(energy).\n",
    "    window = np.sqrt(raw_e) * win_multip\n",
    "    plo, phi = raw_e - window / 2, raw_e + window / 2\n",
    "    nbin_scale = nbin_gain * np.sqrt(raw_e) / raw_e\n",
    "    nbins = int(window) * nbin_scale\n",
    "    ppb = (phi - plo) / nbins\n",
    "    \n",
    "    h, b, var = pgh.get_hist(df_data[etype], range=(plo, phi), dx=ppb)\n",
    "    b = b[1:]\n",
    "    \n",
    "    # get fwhm and select events in the window (ix_evts).  don't need to fit here.\n",
    "    imax = np.argmax(h)\n",
    "    ix_upr = np.where((b > b[imax]) & (h <= np.amax(h)/2))\n",
    "    ix_bot = np.where((b < b[imax]) & (h <= np.amax(h)/2))\n",
    "    \n",
    "    upr_half = b[ix_upr][0]\n",
    "    bot_half = b[ix_bot][-1]\n",
    "    fwhm0 = upr_half - bot_half\n",
    "    sig0 = fwhm0 / 2.355\n",
    "\n",
    "    raw_ctr = b[imax]\n",
    "    raw_lo = raw_ctr - sig0 * nsig_save\n",
    "    raw_hi = raw_ctr + sig0 * nsig_save\n",
    "\n",
    "    # select 'nevt_max' events to save waveforms, but sample evenly throughout the dataset\n",
    "    df_pass = df_data.loc[(df_data[etype] > raw_lo) & (df_data[etype] < raw_hi)]\n",
    "    n_evts = len(df_pass)\n",
    "    n_select = nevt_max if n_evts > nevt_max else n_evts\n",
    "    evts_pass[pk] = df_pass.sample(n_select).sort_values(['cycle','ievt'])\n",
    "    # print(evts_pass[pk])\n",
    "    \n",
    "    axs[ipk].plot(b, h, ds='steps', c='b', lw=1, label=pk + ', ' + etype)\n",
    "    axs[ipk].axvline(raw_lo, c='r', alpha=0.3, label=f'{nsig_save}-sig window\\n{n_evts} cts')\n",
    "    axs[ipk].axvline(raw_hi, c='r', alpha=0.3)\n",
    "    axs[ipk].legend(fontsize=8, loc=2)\n",
    "    axs[ipk].set_xlabel(etype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfe4299-ebb9-461e-ae56-a455a1dcbd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save waveforms for events in peaks into memory as an LH5 table (and to disk).\n",
    "# this can take a long time, which is why it's nice to only run once.\n",
    "\n",
    "sto = lh5.Store()\n",
    "\n",
    "tb_wfs = {} # LH5 tables for each peak\n",
    "\n",
    "# write the data to a temporary LH5 file usable by WaveformBrowser\n",
    "f_wfs = './metadata/wfs_optimizer.lh5' \n",
    "if os.path.exists(f_wfs):\n",
    "    os.remove(f_wfs) # write_object :: append=False can't create a new file\n",
    "\n",
    "for pk, df_evts in evts_pass.items():\n",
    "    print(f'Loading {pk} peak data ...')\n",
    "    \n",
    "    raw_files = dg.lh5_dir + dg.fileDB['raw_path'] + '/' + dg.fileDB['raw_file']\n",
    "    raw_files = list(raw_files)\n",
    "    \n",
    "    df_idxs = df_evts.groupby('cycle').agg({'ievt' : lambda x: list(x)})\n",
    "    raw_idxs = df_idxs['ievt'].values\n",
    "    raw_idxs = list(raw_idxs)\n",
    "    \n",
    "    # this step can take a while, so time it\n",
    "    t_start = time.time()\n",
    "    tb_wfs[pk], n_wfs = sto.read_object(tb_in, raw_files, idx=raw_idxs)\n",
    "    t_elap = (time.time() - t_start) / 60\n",
    "    print(tb_wfs[pk]['waveform']['values'].nda.shape)\n",
    "    print(f'    Waveforms loaded.  Elapsed time: {t_elap:.2f} min.')\n",
    "    \n",
    "    # some handy debug statements looking at h5py dset attrs, etc\n",
    "    # tb_wfs[pk].attrs['datatype'] = 'table{t0, dt, values}' # required by WaveformBrowser\n",
    "    # print(dir(tb_wfs[pk]))\n",
    "    # print(tb_wfs.keys())\n",
    "    # tb_raw = lh5.Table(col_dict={'waveform':tb_wfs[pk]})\n",
    "    # tb_raw.attrs['datatype'] = 'table{waveform}'\n",
    "    \n",
    "    sto.write_object(tb_wfs[pk], f'{tb_in}/{pk}', f_wfs, append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b3149e-0a44-4076-ac0f-c646be693ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For our output file to work with WaveformBrowser, the LH5 Tables, and their\n",
    "# HDF5 attrs etc, all need to be the same.  To make sure this is the case,\n",
    "# compare against the first raw file in our list, which we know is readable\n",
    "# by WaveformBrowser.\n",
    "\n",
    "with h5py.File(f_wfs, 'r') as hf:\n",
    "    print('LH5 columns found :', list(hf[f'{tb_in}/{pk_select}'].keys()))\n",
    "    \n",
    "def print_attrs(name, obj):\n",
    "    print(name)\n",
    "    for key, val in obj.attrs.items():\n",
    "        print(\"    %s: %s\" % (key, val))\n",
    "        \n",
    "# debug -- this is useful for looking at LH5 dataset & attributes\n",
    "        \n",
    "# f_input = raw_files[0]\n",
    "# with h5py.File(f_input, 'r') as hf:\n",
    "#     print('LH5 columns found :', list(hf[f'{tb_in}'].keys()))\n",
    "#     hf.visititems(print_attrs)\n",
    "\n",
    "print('\\nnew wfs file:')\n",
    "f_input = f_wfs\n",
    "with h5py.File(f_input, 'r') as hf:\n",
    "    print('LH5 columns found :', list(hf[f'{tb_in}/{pk_select}'].keys()))\n",
    "    hf.visititems(print_attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1ee942-d170-40f8-a797-3a132c8734a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "# show some example waveforms from all peaks before running WaveformBrowser and ParGrid.\n",
    "# limit to the rising edge because it's more interesting.\n",
    "\n",
    "n_max = 100\n",
    "\n",
    "fig, axs = plt.subplots(1, len(peaks), figsize=(len(peaks)*5, 4))\n",
    "\n",
    "for ipk, (pk, (cal_e, raw_e)) in enumerate(peaks.items()):\n",
    "    \n",
    "    n_wfs, nsamp = tb_wfs[pk]['waveform']['values'].nda.shape\n",
    "    n_lim = n_max if n_wfs > n_max else n_wfs\n",
    "    wfs = tb_wfs[pk]['waveform']['values'].nda[:n_lim,:]\n",
    "    \n",
    "    wf_ctr = nsamp / 2\n",
    "    win_lo, win_hi = int(wf_ctr - 200), int(wf_ctr + 200)\n",
    "    \n",
    "    ts = np.arange(0, len(wfs[0, win_lo:win_hi]))\n",
    "    for iwf in range(wfs.shape[0]):\n",
    "        axs[ipk].plot(ts, wfs[iwf,win_lo:win_hi], lw=2, alpha=0.5)\n",
    "    axs[ipk].plot(np.nan, np.nan, label = f'{pk}, {n_lim} wfs')\n",
    "    axs[ipk].legend(loc=4, fontsize=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df17c965-9d23-4cf5-8785-aad9947b88b3",
   "metadata": {},
   "source": [
    "### 1. Optimize Pole-Zero Correction ('whole-tail')\n",
    "\n",
    "Here, I want to select values for the pole-zero correction (using the `double_pole_zero` calculator) that give the whole tail after the rising edge as flat of a slope as possible.  The tasks here are:\n",
    "\n",
    "- Set up a minimal DSP config file \n",
    "- Declare a `WaveformBrowser` example to show the pole-zero corrected waveform, so that users can draw various wfs\n",
    "- Set up a `ParGrid` class and call `run_one_dsp` for ONE set of parameters, to look at how the **figure of merit** works.\n",
    "- Then in `optimizer_v6_grid.py`, we call the same FOM and run on a larger grid search.\n",
    "\n",
    "**NOTE:** We really don't need very many waveforms to get the pole-zero correction correct (almost all the tails have the same decay constant).  So we can limit this to like 10-100 waveforms and the `ParGrid` search will run much faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbc7f7b-8ad9-4ab7-ba4f-7ddeb5d95455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare the DSP processor list.  later cells will augment these config parameter dict's.\n",
    "\n",
    "dsp_config = {\n",
    "    \"outputs\" : [\"bl\", \"bl_sig\", \"pztail_mean\", \"pztail_sig\"],\n",
    "    \"processors\" : {\n",
    "         \"bl , bl_sig, slope, intercept\":{\n",
    "            \"function\": \"linear_slope_fit\",\n",
    "            \"module\": \"pygama.dsp.processors\",\n",
    "            \"args\" : [\"waveform[:1650]\", \"bl\",\"bl_sig\", \"slope\",\"intercept\"],\n",
    "            \"unit\": [\"ADC\",\"ADC\",\"ADC\",\"ADC\"]\n",
    "        },\n",
    "        \"wf_blsub\":{\n",
    "            \"function\": \"subtract\",\n",
    "            \"module\": \"numpy\",\n",
    "            \"args\": [\"waveform\", \"bl\", \"wf_blsub\"],\n",
    "            \"prereqs\": [\"waveform\", \"bl\"],\n",
    "            \"unit\": \"ADC\",\n",
    "        },\n",
    "        \"wf_pz\": {\n",
    "            \"function\": \"double_pole_zero\",\n",
    "            \"module\": \"pygama.dsp.processors\",\n",
    "            \"prereqs\": [\"wf_blsub\"],\n",
    "            \"args\": [\"wf_blsub\", \"db.pz2.tau1\", \"db.pz2.tau2\",  \"db.pz2.frac\", \"wf_pz\"],\n",
    "            \"defaults\": {\"db.pz2.tau1\":\"187.5*us\", \"db.pz2.tau2\":\"3.17*us\", \"db.pz2.frac\":\"0.035\" },\n",
    "            \"unit\" : \"ADC\"\n",
    "        },\n",
    "         \"pztail_mean , pztail_sig, pz_slope, pz_intercept\":{\n",
    "            \"function\": \"linear_slope_fit\",\n",
    "            \"module\": \"pygama.dsp.processors\",\n",
    "            \"args\" : [\"wf_pz[4250:8000]\", \"pztail_mean\",\"pztail_sig\", \"pz_slope\",\"pz_intercept\"],\n",
    "            \"unit\": [\"ADC\",\"ADC\",\"ADC\",\"ADC\"]\n",
    "        },\n",
    "    }\n",
    "}\n",
    "\n",
    "# try writing to a temporary file\n",
    "# f_dsp = './dsp_tmp.json'\n",
    "# with open(f_dsp, 'w') as f:\n",
    "#     json.dump(dsp_config, f)\n",
    "\n",
    "# user should MANUALLY edit the parameters of interest to get an idea\n",
    "# of which range we should pick to optimize with ParGrid.\n",
    "# this DB will be updated with the 'optimized' parameter choices\n",
    "# (consider this as an output of this notebook).\n",
    "# note: description of the formatting is in pygama.dsp.build_processing_chain\n",
    "dsp_db = {\n",
    "    \"pz2\" : {\n",
    "        \"tau1\" : \"51*us\",\n",
    "        \"tau2\" : \"2*us\",\n",
    "        \"frac\" : 0.04\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df58fba5-ee5d-499b-96df-e422602576d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- waveform browser step -- \n",
    "\n",
    "# load our skim waveforms file\n",
    "f_input = f_wfs \n",
    "tb_input = f'{tb_in}/{pk_select}'\n",
    "\n",
    "# debug - load wf browser with raw file 0 & preexisting config\n",
    "# dsp_config = os.path.expandvars(f'$CAGE_SW/processing/metadata/dsp/dsp_06.json')\n",
    "# f_input = raw_files[0] # testing, has correct datatypes\n",
    "# tb_input = f'{tb_in}'\n",
    "\n",
    "pprint(dsp_db)\n",
    "\n",
    "b = wfb(f_input, tb_input, dsp_config,\n",
    "        waveforms=['wf_blsub', 'wf_pz'],\n",
    "        database=dsp_db,\n",
    "        # selection = cut,\n",
    "        wf_styles=[{'linestyle':['-']}, {'linestyle':[':']}],\n",
    "        #legend=['wf_blsub {bl:.2f}', 'pz-corrected'], # displaying the bl value is tricky\n",
    "        legend_opts={'loc':\"lower right\"},\n",
    "        #lines=['bl'],\n",
    "        x_lim=(38000, 80000)\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9903aad-7dce-4891-b890-0918a657eb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "b.draw_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2cf356-90aa-4d29-a65d-d3596b0023f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "# -- EXAMPLE -- run_one_dsp and evaluate a figure of merit.\n",
    "# This is automated by the ParGrid class, but it's good to be able to visualize & make plots of what's happening.\n",
    "\n",
    "col_name = 'pztail_sig'\n",
    "\n",
    "def mean_val(tb, verbosity):\n",
    "    return np.average(tb[col_name].nda)\n",
    "\n",
    "# limit the number of wfs, we only need ~10--50 to get the pz correction right.  \n",
    "# it's easier to reload from the file than to try and slice the in-memory `tb_wfs[pk_select]`.\n",
    "nwfs_lim = 10\n",
    "sto = lh5.Store()\n",
    "tb_wfs_slim, n_wfs = sto.read_object(f'{tb_in}/{pk_select}', f_wfs, n_rows=nwfs_lim)\n",
    "\n",
    "tb_out = run_one_dsp(tb_wfs_slim, dsp_config, db_dict=dsp_db, verbosity=1, )\n",
    "\n",
    "mean = mean_val(tb_out, 0)\n",
    "xlo, xhi, xpb = mean - mean/2, mean + mean/2, 0.5\n",
    "h, b, var = pgh.get_hist(tb_out[col_name].nda, range=(xlo, xhi), dx=xpb)\n",
    "plt.plot(b[1:], h, ds='steps', c='b')\n",
    "plt.xlabel(col_name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d7e790-0f0d-434b-a129-29a24b88d1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ParGrid setup\n",
    "# internally this calls run_one_dsp with our figure of merit function.\n",
    "# In the notebook we don't want to run on too many points,\n",
    "# We can run a really FINE grid search in `optimizer_v6_grid.py` on the batch system.\n",
    "\n",
    "pg = ParGrid()\n",
    "\n",
    "# vary tau1, tau2, and frac\n",
    "tau1_arr = np.linspace(51, 52, 6)\n",
    "tau2_arr = np.linspace(5.5, 7, 6)\n",
    "frac_arr = np.linspace(0.03, 0.05, 4)\n",
    "\n",
    "pg.add_dimension('wf_pz', 1, [f\"{t:.2f}*us\" for t in tau1_arr])\n",
    "pg.add_dimension('wf_pz', 2, [f\"{t:.2f}*us\" for t in tau2_arr])\n",
    "pg.add_dimension('wf_pz', 3, [f\"{t:.3f}\" for t in frac_arr])\n",
    "\n",
    "print('tau1:', tau1_arr)\n",
    "print('tau2:', tau2_arr)\n",
    "print('frac:', frac_arr)\n",
    "ngrid = pg.get_n_grid_points()\n",
    "print('grid points to search:', ngrid)\n",
    "\n",
    "# the more waveforms we have, the longer it will take to run one grid point\n",
    "nwfs = tb_wfs_slim['waveform']['values'].nda.shape[0]\n",
    "print('wfs to reprocess:', nwfs * ngrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dc6766-ff70-4a81-8566-ca5cb95928bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the grid search.\n",
    "\n",
    "# NOTE: the fom_function does NOT support additional function arguments.\n",
    "fom_vals = run_grid(tb_wfs_slim, dsp_config, pg, mean_val, verbosity=0)\n",
    "\n",
    "# unpack the results into a DataFrame.  \n",
    "# have to iterate thru the n-dimensional grid\n",
    "grid_nd = []\n",
    "ix = pg.get_zero_indices()\n",
    "while True:\n",
    "    row = []\n",
    "    for i_dim, i_par in enumerate(ix):\n",
    "        name, i_arg, value_str, _ = pg.get_data(i_dim, i_par)\n",
    "        #if '*' in value_str:\n",
    "        #    val = float(value_str.split('*')[0])\n",
    "        #else:\n",
    "        #    val = float(value_str)\n",
    "        row.append(value_str)\n",
    "    grid_nd.append(row)\n",
    "    if not pg.iterate_indices(ix): break\n",
    "\n",
    "df_grid = pd.DataFrame(grid_nd, columns=['tau1','tau2','frac'])\n",
    "\n",
    "results_1d = fom_vals.reshape(-1, pg.get_n_grid_points())\n",
    "df_grid['fom'] = results_1d[0]\n",
    "\n",
    "print(\"NOTE: if one of the best settings is at the upper/lower limit of your parameter grid,\",\n",
    "      \"\\nyou probably need to adjust the grid to find the true min.\")\n",
    "\n",
    "# df_grid # show full df\n",
    "df_best = df_grid.sort_values('fom')[:5] # show 5 best settings\n",
    "df_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d41cf48-665a-4d93-af20-824be529f22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally, update the dsp_db with the best result\n",
    "\n",
    "dbest = df_best.iloc[0].to_dict()\n",
    "\n",
    "for par, val in dbest.items():\n",
    "    if par == 'fom': continue\n",
    "    dsp_db['pz2'][par] = val\n",
    "\n",
    "print(\"NOTE: you can go back and re-run the WaveformBrowser step now,\",\n",
    "     \"\\nto see the effect of the updated PZ values.\")\n",
    "dsp_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6136d220-5240-4216-9fb7-6dfa0c219ff9",
   "metadata": {},
   "source": [
    "## 2. Energy Trapezoid Optimization\n",
    "\n",
    "Our main energy estimator is `trapEftp`, which uses a combination of different trapezoid settings.  The most important ones to get right are in the  \"energy trapezoid\" `wf_trap` -- the trap filter with a long integration time.  This is used for `trapEmax`.  The fixed-time-pickoff calculation also uses an asymmetric trapezoid to find `t0`, and then we set a \"pickoff time\".  Jason and Ian have said that as long as the pickoff time selects a point on the flat top of the energy trapezoid, its value is rather arbitrary.  Similarly, the `t0` calculator is fairly robust too, and these parameters shouldn't need to be varied as much as the energy trap parameters.\n",
    "\n",
    "So here, we're going to optimize `db.etrap.rise`, `db.etrap.flat`, and for fun we can also optimize `db.pz2.tau1` to see if we get a different value than what we got above.  I bet we will ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd6dea8-3fbe-442d-beab-525a787bfe01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-declare dsp_config to contain energy trapezoid calculators.\n",
    "# this is visually simpler than trying to augment the existing dictionary.\n",
    "# however, we should update the dsp_db dict, since it's the \"output\" of this notebook.\n",
    "\n",
    "dsp_config = {\n",
    "    \"outputs\" : [\"tp_0\", \"trapEmax\", \"atrap_max\", \"trapEftp\", \"tp_ftp\"],\n",
    "    \"processors\" : {\n",
    "         \"bl , bl_sig, slope, intercept\":{\n",
    "            \"function\": \"linear_slope_fit\",\n",
    "            \"module\": \"pygama.dsp.processors\",\n",
    "            \"args\" : [\"waveform[:1650]\", \"bl\",\"bl_sig\", \"slope\",\"intercept\"],\n",
    "            \"unit\": [\"ADC\",\"ADC\",\"ADC\",\"ADC\"]\n",
    "        },\n",
    "        \"wf_blsub\":{\n",
    "            \"function\": \"subtract\",\n",
    "            \"module\": \"numpy\",\n",
    "            \"args\": [\"waveform\", \"bl\", \"wf_blsub\"],\n",
    "            \"prereqs\": [\"waveform\", \"bl\"],\n",
    "            \"unit\": \"ADC\",\n",
    "        },\n",
    "        \"wf_pz\": {\n",
    "            \"function\": \"double_pole_zero\",\n",
    "            \"module\": \"pygama.dsp.processors\",\n",
    "            \"prereqs\": [\"wf_blsub\"],\n",
    "            \"args\": [\"wf_blsub\", \"db.pz2.tau1\", \"db.pz2.tau2\",  \"db.pz2.frac\", \"wf_pz\"],\n",
    "            \"defaults\": {\"db.pz2.tau1\":\"187.5*us\", \"db.pz2.tau2\":\"3.17*us\", \"db.pz2.frac\":\"0.035\" },\n",
    "            \"unit\" : \"ADC\"\n",
    "        },\n",
    "        \"wf_etrap\": {\n",
    "            \"function\": \"trap_norm\",\n",
    "            \"module\": \"pygama.dsp.processors\",\n",
    "            \"prereqs\": [\"wf_pz\"],\n",
    "            \"args\": [\"wf_pz\", \"db.etrap.rise\", \"db.etrap.flat\", \"wf_etrap\"],\n",
    "            \"defaults\" : {\"db.etrap.rise\":\"4*us\", \"db.etrap.flat\":\"1*us\"},\n",
    "            \"unit\": \"ADC\"\n",
    "        },\n",
    "        \"wf_atrap\": {\n",
    "            \"function\": \"asym_trap_filter\",\n",
    "            \"module\": \"pygama.dsp.processors\",\n",
    "            \"prereqs\": [\"wf_pz\"],\n",
    "            # \"args\": [\"wf_pz\", \"round(0.1*us)\", \"round(1*us)\", \"round(4*us)\", \"wf_atrap\"], # ian's\n",
    "            \"args\": [\"wf_pz\", \"db.atrap.rise\", \"db.atrap.flat\", \"db.atrap.fall\", \"wf_atrap\"], # clint's\n",
    "            \"defaults\" : {\"db.atrap.rise\":\"20*ns\", \"db.atrap.flat\":\"1*us\",\"db.atrap.fall\":\"4*us\"},\n",
    "            \"unit\": \"ADC\"\n",
    "        },\n",
    "        \"trapEmax\": {\n",
    "            \"function\": \"amax\",\n",
    "            \"module\": \"numpy\",\n",
    "            \"args\": [\"wf_etrap\", 1, \"trapEmax\"],\n",
    "            \"kwargs\": {\"signature\":\"(n),()->()\", \"types\":[\"fi->f\"]},\n",
    "            \"unit\": \"ADC\",\n",
    "            \"prereqs\": [\"wf_etrap\"]\n",
    "        },\n",
    "         \"atrap_max\": {\n",
    "             \"function\": \"argmax\",\n",
    "              \"module\": \"numpy\",\n",
    "              \"args\": [\"wf_atrap\", 1, \"atrap_max\"],\n",
    "              \"kwargs\": {\"signature\":\"(n),()->()\", \"types\":[\"fi->i\"]},\n",
    "              \"unit\": \"ADC\",\n",
    "              \"prereqs\": [\"wf_atrap\"]\n",
    "        },\n",
    "        \"tmax\": {\n",
    "            \"function\": \"argmax\",\n",
    "            \"module\": \"numpy\",\n",
    "            \"args\": [\"wf_atrap\", 1, \"tmax\"],\n",
    "            \"kwargs\": {\"signature\":\"(n),()->()\", \"types\":[\"fi->i\"]},\n",
    "            \"unit\": \"ns\"\n",
    "        },\n",
    "        \"tp_0\": {\n",
    "            \"function\": \"time_point_thresh\",\n",
    "            \"module\": \"pygama.dsp.processors\",\n",
    "            \"args\": [\"wf_atrap\", 0, \"tmax\", 0, \"tp_0\"],\n",
    "            \"unit\": \"ns\",\n",
    "        },\n",
    "         \"trapEftp\": {\n",
    "            \"function\": \"fixed_time_pickoff\",\n",
    "            \"module\": \"pygama.dsp.processors\",\n",
    "            \"args\": [\"wf_etrap\", \"db.tp_ftp.ftp\", \"trapEftp\"],\n",
    "            \"defaults\" : {\"db.tp_ftp.ftp\":\"tp_0 + 5.5*us\"},\n",
    "            \"unit\": \"ADC\",\n",
    "            \"prereqs\": [\"wf_etrap\", \"tp_0\"]\n",
    "        },\n",
    "        \"tp_ftp\" : {\n",
    "            \"function\":\"add\",\n",
    "            \"module\":\"numpy\",\n",
    "            \"args\":[\"tp_0\", \"db.tp_ftp.ftp\", \"tp_ftp\"],\n",
    "            \"defaults\" : {\"db.tp_ftp.ftp\":\"tp_0 + 5.5*us\"},\n",
    "            \"prereqs\":[\"tp_0\"],\n",
    "            \"unit\":\"ns\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# add parameters to dsp_db\n",
    "dsp_db['etrap'] = {\"rise\":\"4*us\", \"flat\":\"2*us\"}\n",
    "dsp_db['atrap'] = {\"rise\":\"20*ns\", \"flat\":\"1*us\", \"fall\":\"4*us\"}\n",
    "dsp_db['tp_ftp'] = {\"ftp\":\"tp_0 + 5.5*us\"} # << this gets trapEftp correct!!\n",
    "# dsp_db['tp_ftp'] = {\"ftp\":\"5.5*us\"} # << this one draws correctly on the plot !! weird.\n",
    "\n",
    "# pprint(dsp_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5581961-15a0-46aa-b71d-47e761677064",
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- waveform browser step -- \n",
    "# user should MANUALLY edit the parameters of interest to get an idea\n",
    "# of which ranges & parameters we should pick to optimize with ParGrid\n",
    "\n",
    "# load our skim waveforms file\n",
    "f_input = f_wfs \n",
    "tb_input = f'{tb_in}/{pk_select}'\n",
    "\n",
    "print('DB input parameters:')\n",
    "pprint(dsp_db)\n",
    "\n",
    "b = wfb(f_input, tb_input, dsp_config,\n",
    "        waveforms=['wf_blsub', 'wf_pz', 'wf_etrap', 'wf_atrap'],\n",
    "        database=dsp_db,\n",
    "        legend=['wf_blsub', 'wf_pz', 'wf_etrap', 'wf_atrap'],\n",
    "        # lines=['trapEftp', 'tp_ftp', 'tp_0'], # hmm, I can't get any of these to work, need to ask ian\n",
    "        x_lim=(38000, 55000)\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67532b68-f43e-412c-be81-bdd074238ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "b.draw_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f71fe9a-aac0-4691-b029-e4b1f23c13f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "# -- EXAMPLE: try a couple different figures of merit to optimize the\n",
    "# height/width of our test peak.\n",
    "\n",
    "# ene_type = 'trapEftp' # this one was giving me issues\n",
    "ene_type = 'trapEmax' # <-- need to use this one\n",
    "\n",
    "win_multip = 0.5\n",
    "nbin_gain = 100\n",
    "\n",
    "def peak_height(tb, verbosity):\n",
    "    raw_e = np.mean(tb[ene_type].nda)\n",
    "    window = np.sqrt(raw_e) * win_multip\n",
    "    plo, phi = raw_e - window / 2, raw_e + window / 2\n",
    "    nbin_scale = nbin_gain * np.sqrt(raw_e) / raw_e\n",
    "    nbins = int(window) * nbin_scale\n",
    "    ppb = (phi - plo) / nbins\n",
    "    h, b, var = pgh.get_hist(tb[ene_type].nda, range=(plo, phi), dx=ppb)\n",
    "    # plt.plot(b[1:], h, ds='steps')\n",
    "    # plt.show()\n",
    "    return np.max(h)\n",
    "\n",
    "\n",
    "def peak_width(tb, verbosity, make_plot=False):\n",
    "    \n",
    "    # histogram the data\n",
    "    raw_e = np.mean(tb[ene_type].nda)\n",
    "    window = np.sqrt(raw_e) * win_multip\n",
    "    plo, phi = raw_e - window / 2, raw_e + window / 2\n",
    "    nbin_scale = nbin_gain * np.sqrt(raw_e) / raw_e\n",
    "    nbins = int(window) * nbin_scale\n",
    "    ppb = (phi - plo) / nbins\n",
    "    h, bins, var = pgh.get_hist(tb[ene_type].nda, range=(plo, phi), dx=ppb)\n",
    "    b = bins[1:]\n",
    "\n",
    "    # get initial guesses for simple Gauss fit\n",
    "    imax = np.argmax(h)\n",
    "    ix_upr = np.where((b > b[imax]) & (h <= np.amax(h)/2))\n",
    "    ix_bot = np.where((b < b[imax]) & (h <= np.amax(h)/2))\n",
    "    upr_half = b[ix_upr][0]\n",
    "    bot_half = b[ix_bot][-1]\n",
    "    fwhm0 = upr_half - bot_half\n",
    "    sig0 = fwhm0 / 2.355\n",
    "    amp0 = np.amax(h) * fwhm0\n",
    "    p_init = [b[imax], sig0, amp0]\n",
    "\n",
    "    # run curve_fit through pygama's wrapper function\n",
    "    fit_func = pgf.gauss\n",
    "    p_fit, p_cov = pgf.fit_hist(fit_func, h, bins,\n",
    "                                var=var, guess=p_init)\n",
    "    p_err = np.sqrt(np.diag(p_cov))\n",
    "\n",
    "    if make_plot:\n",
    "        plt.plot(b, h, ds='steps', c='b', lw=1, label=pk_select + ', ' + etype)\n",
    "        xfit = np.arange(plo, phi, ppb * 0.1)\n",
    "        plt.plot(xfit, fit_func(xfit, *p_init), '-', c='orange', label='init')\n",
    "        plt.plot(xfit, fit_func(xfit, *p_fit), '-', c='red', label='fit')\n",
    "        plt.legend(fontsize=8, loc=2)\n",
    "        plt.xlabel(etype)\n",
    "        plt.show()\n",
    "\n",
    "    return p_fit[1] * 2.355 # fwhm\n",
    "\n",
    "print('DB parameters:')\n",
    "pprint(dsp_db)\n",
    "\n",
    "# run dsp -- for some reason it's not printing the db.etrap lookup, but seems to use it ...\n",
    "tb_out = run_one_dsp(tb_wfs[pk_select], dsp_config, db_dict=dsp_db, verbosity=1)\n",
    "\n",
    "# this is how i examined the problem with tp_ftp and trapEftp \n",
    "print(tb_out.keys())\n",
    "df = tb_out.get_dataframe()\n",
    "\n",
    "# check figure of merit\n",
    "height = peak_height(tb_out, 0)\n",
    "print(\"counts in max bin:\", height)\n",
    "\n",
    "fwhm = peak_width(tb_out, 0, True)\n",
    "print(\"fwhm:\", fwhm)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf6db16-db5c-468d-86a0-7bc6bad729a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ParGrid setup\n",
    "# internally this calls run_one_dsp with our figure of merit function.\n",
    "# In the notebook we don't want to run on too many points,\n",
    "# We can run a really FINE grid search in `optimizer_v6_grid.py` on the batch system.\n",
    "\n",
    "pg = ParGrid()\n",
    "\n",
    "# vary rise, flat, and pz\n",
    "rise_arr = np.linspace(8, 11, 9)\n",
    "flat_arr = np.linspace(2, 4, 3)\n",
    "# pz_arr = np.linspace(51, 51, 1)\n",
    "\n",
    "pg.add_dimension('wf_etrap', 1, [f\"{t:.2f}*us\" for t in rise_arr])\n",
    "pg.add_dimension('wf_etrap', 2, [f\"{t:.2f}*us\" for t in flat_arr])\n",
    "# pg.add_dimension('wf_pz', 3, [f\"{t:.2f}*us\" for t in pz_arr])\n",
    "\n",
    "print('rise:', rise_arr)\n",
    "print('flat:', flat_arr)\n",
    "# print('pz:', pz_arr)\n",
    "ngrid = pg.get_n_grid_points()\n",
    "print('grid points to search:', ngrid)\n",
    "\n",
    "# the more waveforms we have, the longer it will take to run one grid point\n",
    "nwfs = tb_wfs[pk_select]['waveform']['values'].nda.shape[0]\n",
    "print('wfs to reprocess:', nwfs * ngrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cc3c30-6a23-4f69-a306-237616d09403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the grid search.\n",
    "\n",
    "# NOTE: the fom_function does NOT support additional function arguments.\n",
    "fom_vals = run_grid(tb_wfs[pk_select], dsp_config, pg, peak_width, db_dict=dsp_db, verbosity=0)\n",
    "\n",
    "# unpack the results into a DataFrame.  \n",
    "# have to iterate thru the n-dimensional grid\n",
    "grid_nd = []\n",
    "ix = pg.get_zero_indices()\n",
    "while True:\n",
    "    row = []\n",
    "    for i_dim, i_par in enumerate(ix):\n",
    "        name, i_arg, value_str, _ = pg.get_data(i_dim, i_par)\n",
    "        #if '*' in value_str:\n",
    "        #    val = float(value_str.split('*')[0])\n",
    "        #else:\n",
    "        #    val = float(value_str)\n",
    "        row.append(value_str)\n",
    "    grid_nd.append(row)\n",
    "    if not pg.iterate_indices(ix): break\n",
    "\n",
    "df_grid = pd.DataFrame(grid_nd, columns=['rise','flat'])\n",
    "\n",
    "results_1d = fom_vals.reshape(-1, pg.get_n_grid_points())\n",
    "df_grid['fom'] = results_1d[0]\n",
    "\n",
    "print(\"NOTE: if one of the best settings is at the upper/lower limit of your parameter grid,\",\n",
    "      \"\\nyou probably need to adjust the grid to find the true min.\")\n",
    "\n",
    "# df_grid # show full df\n",
    "df_best = df_grid.sort_values('fom')\n",
    "df_best[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5dde95-5ed6-4d5c-a9b0-5fcd6e27aaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the dsp_db with the best result.\n",
    "print(df_best.iloc[0])\n",
    "dbest = df_grid.sort_values('fom').iloc[0].to_dict()\n",
    "\n",
    "for par, val in dbest.items():\n",
    "    if par == 'fom': continue\n",
    "    dsp_db['etrap'][par] = val\n",
    "    \n",
    "# tp_ftp should be updated to tp_0 + rise + flat/2 automatically, or you're gonna forget ...\n",
    "rt = float(dsp_db['etrap']['rise'].split('*')[0])\n",
    "ft = float(dsp_db['etrap']['flat'].split('*')[0])\n",
    "dsp_db['tp_ftp']['ftp'] = f'tp_0 + {rt+ft/2}*us'\n",
    "\n",
    "print(\"NOTE 1: you can go back and re-run the WaveformBrowser step now,\",\n",
    "     \"\\nto see the effect of the updated values.\")\n",
    "\n",
    "dsp_db\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44727bf0-f557-4402-a555-0647f578225f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "# run dsp with the best result and check resolution\n",
    "\n",
    "print('DB parameters:')\n",
    "pprint(dsp_db)\n",
    "# pprint(dsp_config)\n",
    "\n",
    "# run dsp\n",
    "tb_out = run_one_dsp(tb_wfs[pk_select], dsp_config, db_dict=dsp_db, verbosity=1)\n",
    "\n",
    "# this is how i examined the problem with tp_ftp and trapEftp \n",
    "print(tb_out.keys())\n",
    "df = tb_out.get_dataframe()\n",
    "\n",
    "\n",
    "# check figure of merit\n",
    "height = peak_height(tb_out, 0)\n",
    "print(\"counts in max bin:\", height)\n",
    "\n",
    "fwhm = peak_width(tb_out, 0, True)\n",
    "print(\"fwhm:\", fwhm)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed51e7d0-9110-45c9-900b-0e0f0b0d46ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load our skim waveforms file\n",
    "f_input = f_wfs \n",
    "tb_input = f'{tb_in}/{pk_select}'\n",
    "\n",
    "print('DB input parameters:')\n",
    "pprint(dsp_db)\n",
    "\n",
    "b = wfb(f_input, tb_input, dsp_config,\n",
    "        waveforms=['wf_blsub', 'wf_pz', 'wf_etrap', 'wf_atrap'],\n",
    "        database=dsp_db,\n",
    "        legend=['wf_blsub', 'wf_pz', 'wf_etrap', 'wf_atrap'],\n",
    "        lines=['tp_ftp', 'tp_0', 'trapEftp', 'tp_ftp'],\n",
    "        x_lim=(38000, 80000)\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241cbcb7-17fd-4bf8-afd2-7d2c57be7ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "b.draw_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a9f0ca-d768-44a8-ab4f-b9551741a10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(dsp_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066effd8-7b9f-449e-86b5-a66c6e7ff6de",
   "metadata": {},
   "source": [
    "## 3. DCR Parameter Optimization\n",
    "\n",
    "DCR is basically measuring \"the slope of the tail\" of each waveform.  We know that alpha events tend to have a higher slope, meaning that some excess charge is \"trickling in\" to the detector much more slowly than the bulk of the charge collection, which creates the rising edge of a signal.  To calculate it, instead of fitting the tail (which is slow), we just take the average in two ~1 us windows on the tail, and subtract them: `DCR = win2 - win1 / len(win)`\n",
    "\n",
    "In pygama this is equivalent to calculating a trapezoid filter with `rise = win1, win2` and `flat = (spacing between windows)` (typically 10--20 usec), and then evaluating the trapezoid at its first point (a fixed-time pickoff).\n",
    "\n",
    "In previous CAGE analyses, we've found that varying the window where we optimize the pole-zero correction (so, making another choice than `[4200:8000]` for the tail) can lead to better alpha/gamma event separation.  To optimize DCR, there are sort of two steps:\n",
    "1. Take a small population of gamma events (so, our 40K or 208TL sample waveforms) and tune `dcr` such that it's as close to zero as possible.  Note there may be an overall trend with energy that you can't really get rid of.\n",
    "2. Check the alpha-gamma separation in a 2D plot.  Access the first few files in the `raw_files` array to get enough statistics.  This can also take a few minutes to complete `run_one_dsp` so keeping the array sizes as small as possible is useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b65602-996f-4b20-8920-1972f5fda9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsp_config = {\n",
    "    \"outputs\" : [\"tp_0\", \"trapEmax\", \"atrap_max\", \"trapEftp\", \"tp_ftp\", \"dcr\"],\n",
    "    \"processors\" : {\n",
    "         \"bl , bl_sig, slope, intercept\":{\n",
    "            \"function\": \"linear_slope_fit\",\n",
    "            \"module\": \"pygama.dsp.processors\",\n",
    "            \"args\" : [\"waveform[:3500]\", \"bl\",\"bl_sig\", \"slope\",\"intercept\"],\n",
    "            \"unit\": [\"ADC\",\"ADC\",\"ADC\",\"ADC\"]\n",
    "        },\n",
    "        \"wf_blsub\":{\n",
    "            \"function\": \"subtract\",\n",
    "            \"module\": \"numpy\",\n",
    "            \"args\": [\"waveform\", \"bl\", \"wf_blsub\"],\n",
    "            \"prereqs\": [\"waveform\", \"bl\"],\n",
    "            \"unit\": \"ADC\",\n",
    "        },\n",
    "        \"wf_pz\": {\n",
    "            \"function\": \"double_pole_zero\",\n",
    "            \"module\": \"pygama.dsp.processors\",\n",
    "            \"prereqs\": [\"wf_blsub\"],\n",
    "            \"args\": [\"wf_blsub\", \"db.pz2.tau1\", \"db.pz2.tau2\",  \"db.pz2.frac\", \"wf_pz\"],\n",
    "            \"defaults\": {\"db.pz2.tau1\":\"187.5*us\", \"db.pz2.tau2\":\"3.17*us\", \"db.pz2.frac\":\"0.035\" },\n",
    "            \"unit\" : \"ADC\"\n",
    "        },\n",
    "        \"wf_etrap\": {\n",
    "            \"function\": \"trap_norm\",\n",
    "            \"module\": \"pygama.dsp.processors\",\n",
    "            \"prereqs\": [\"wf_pz\"],\n",
    "            \"args\": [\"wf_pz\", \"db.etrap.rise\", \"db.etrap.flat\", \"wf_etrap\"],\n",
    "            \"defaults\" : {\"db.etrap.rise\":\"4*us\", \"db.etrap.flat\":\"1*us\"},\n",
    "            \"unit\": \"ADC\"\n",
    "        },\n",
    "\"wf_atrap\": {\n",
    "            \"function\": \"asym_trap_filter\",\n",
    "            \"module\": \"pygama.dsp.processors\",\n",
    "            \"prereqs\": [\"wf_pz\"],\n",
    "            # \"args\": [\"wf_pz\", \"round(0.1*us)\", \"round(1*us)\", \"round(4*us)\", \"wf_atrap\"], # ian's\n",
    "            \"args\": [\"wf_pz\", \"db.atrap.rise\", \"db.atrap.flat\", \"db.atrap.fall\", \"wf_atrap\"], # clint's\n",
    "            \"defaults\" : {\"db.atrap.rise\":\"20*ns\", \"db.atrap.flat\":\"1*us\",\"db.atrap.fall\":\"4*us\"},\n",
    "            \"unit\": \"ADC\"\n",
    "        },\n",
    "        \"trapEmax\": {\n",
    "            \"function\": \"amax\",\n",
    "            \"module\": \"numpy\",\n",
    "            \"args\": [\"wf_etrap\", 1, \"trapEmax\"],\n",
    "            \"kwargs\": {\"signature\":\"(n),()->()\", \"types\":[\"fi->f\"]},\n",
    "            \"unit\": \"ADC\",\n",
    "            \"prereqs\": [\"wf_etrap\"]\n",
    "        },\n",
    "         \"atrap_max\": {\n",
    "             \"function\": \"argmax\",\n",
    "              \"module\": \"numpy\",\n",
    "              \"args\": [\"wf_atrap\", 1, \"atrap_max\"],\n",
    "              \"kwargs\": {\"signature\":\"(n),()->()\", \"types\":[\"fi->i\"]},\n",
    "              \"unit\": \"ADC\",\n",
    "              \"prereqs\": [\"wf_atrap\"]\n",
    "        },\n",
    "        \"tmax\": {\n",
    "            \"function\": \"argmax\",\n",
    "            \"module\": \"numpy\",\n",
    "            \"args\": [\"wf_atrap\", 1, \"tmax\"],\n",
    "            \"kwargs\": {\"signature\":\"(n),()->()\", \"types\":[\"fi->i\"]},\n",
    "            \"unit\": \"ns\"\n",
    "        },\n",
    "        \"tp_0\": {\n",
    "            \"function\": \"time_point_thresh\",\n",
    "            \"module\": \"pygama.dsp.processors\",\n",
    "            \"args\": [\"wf_atrap\", 0, \"tmax\", 0, \"tp_0\"],\n",
    "            \"unit\": \"ns\",\n",
    "        },\n",
    "         \"trapEftp\": {\n",
    "            \"function\": \"fixed_time_pickoff\",\n",
    "            \"module\": \"pygama.dsp.processors\",\n",
    "            \"args\": [\"wf_etrap\", \"db.tp_ftp.ftp\", \"trapEftp\"],\n",
    "            \"defaults\" : {\"db.tp_ftp.ftp\":\"tp_0 + 5.5*us\"},\n",
    "            \"unit\": \"ADC\",\n",
    "            \"prereqs\": [\"wf_etrap\", \"tp_0\"]\n",
    "        },\n",
    "        \"tp_ftp\" : {\n",
    "            \"function\":\"add\",\n",
    "            \"module\":\"numpy\",\n",
    "            \"args\":[\"tp_0\", \"db.tp_ftp.ftp\", \"tp_ftp\"],\n",
    "            \"defaults\" : {\"db.tp_ftp.ftp\":\"tp_0 + 5.5*us\"},\n",
    "            \"prereqs\":[\"tp_0\"],\n",
    "            \"unit\":\"ns\"\n",
    "        },\n",
    "        \"wf_pz_dcr\": {\n",
    "            \"function\": \"double_pole_zero\",\n",
    "            \"module\": \"pygama.dsp.processors\",\n",
    "            \"prereqs\": [\"wf_blsub\"],\n",
    "            \"args\": [\"wf_blsub\", \"db.dcr_pz.tau1\", \"db.dcr_pz.tau2\",  \"db.dcr_pz.frac\", \"wf_pz_dcr\"],\n",
    "            \"defaults\": {\"db.dcr_pz.tau1\":\"50*us\", \"db.dcr_pz.tau2\":\"6*us\", \"db.dcr_pz.frac\":\"0.04\" },\n",
    "            \"unit\" : \"ADC\"\n",
    "        },\n",
    "        \"wf_dcr_trap\": {\n",
    "            \"function\": \"trap_norm\",\n",
    "            \"module\": \"pygama.dsp.processors\",\n",
    "            \"args\": [\"wf_pz_dcr\", \"db.dcr_trap.rise\", \"db.dcr_trap.flat\", \"wf_dcr_trap\"],\n",
    "            \"defaults\" : {\"db.dcr_trap.rise\":\"7.5*us\", \"db.dcr_trap.flat\":\"22.5*us\"},\n",
    "            \"unit\": \"ADC\",\n",
    "            \"prereqs\": [\"wf_pz_dcr\"]\n",
    "        },\n",
    "        \"dcr\": {\n",
    "            \"function\": \"fixed_time_pickoff\",\n",
    "            \"module\": \"pygama.dsp.processors\",\n",
    "            \"args\": [\"wf_dcr_trap\", \"db.dcr.ftp\", \"dcr\"],\n",
    "            \"defaults\" : {\"db.dcr.ftp\" : \"79*us\"},\n",
    "            \"unit\": \"ADC\",\n",
    "            \"prereqs\": [\"wf_dcr_trap\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# add parameters to dsp_db\n",
    "# dsp_db['dcr_pz'] = {\"tau1\":\"52*us\", \"tau2\":\"6.*us\", \"frac\":\"0.04\"}\n",
    "dsp_db['dcr_pz'] = dsp_db['pz2'] # set equal to best result from above\n",
    "# dsp_db['dcr_trap'] = {\"rise\":\"7.5*us\", \"flat\":\"22.5*us\"}\n",
    "dsp_db['dcr_trap'] = {'flat': '20.33*us', 'rise': '7.00*us'}\n",
    "dsp_db['dcr'] = {\"ftp\":\"80*us\"}\n",
    "\n",
    "pprint(dsp_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63852f53-c705-49ca-b5d6-bebc8b93f597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# browse waveforms\n",
    "\n",
    "f_input = f_wfs \n",
    "tb_input = f'{tb_in}/{pk_select}'\n",
    "\n",
    "print('DB input parameters:')\n",
    "pprint(dsp_db)\n",
    "\n",
    "b = wfb(f_input, tb_input, dsp_config,\n",
    "        waveforms=['wf_blsub', 'wf_pz_dcr', 'wf_dcr_trap'],\n",
    "        database=dsp_db,\n",
    "        # legend=['wf_blsub', 'wf_pz_dcr', 'wf_dcr_trap'],\n",
    "        lines=['dcr'],\n",
    "        x_lim=(38000, 80000)\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33541201-eb61-4d3e-a695-61cc4175a962",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "b.draw_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e5c81b-9929-4f82-9b6d-a517a73af270",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "# EXAMPLE -- run_one_dsp with this config file and check the output dataframe.\n",
    "\n",
    "def mean_val(tb, verbosity, make_plot=False):\n",
    "    \n",
    "    if make_plot:\n",
    "        ps = pd.Series(tb['dcr'].nda)\n",
    "        ps.hist()\n",
    "    \n",
    "    return np.average(tb[\"dcr\"].nda)\n",
    "\n",
    "print('DB parameters:')\n",
    "pprint(dsp_db)\n",
    "\n",
    "# run dsp -- for some reason it's not printing the db.etrap lookup, but seems to use it ...\n",
    "tb_out = run_one_dsp(tb_wfs[pk_select], dsp_config, db_dict=dsp_db, verbosity=1)\n",
    "\n",
    "print(tb_out.keys())\n",
    "df = tb_out.get_dataframe()\n",
    "\n",
    "# check figure of merit\n",
    "mean_dcr = mean_val(tb_out, 0, True)\n",
    "print(\"mean:\", mean_dcr)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bbbbaa-6f51-4d62-9398-3e30843b0742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ParGrid setup\n",
    "\n",
    "\n",
    "pg = ParGrid()\n",
    "\n",
    "# we can vary: dcr_pz.tau1, dcr_pz.tau2, dcr_trap.rise, dcr_trap.flat,\n",
    "# but the most sensitive parameters should be tau1 and tau2.\n",
    "# NOTE: we also may want to vary the waveform window, which can only be set in dsp_config\n",
    "\n",
    "# optimizing tau didn't really do that well, it introduced a lot of curvature.\n",
    "# seems like it's better to use the best-fit pz corrected waveform found above,\n",
    "# and then vary rise/flat to try to pin the dcr values of 2615 to 0 ...\n",
    "# tau1_arr = np.linspace(50, 53, 10)\n",
    "# tau2_arr = np.linspace(2, 4, 3)\n",
    "# pg.add_dimension('wf_pz_dcr', 1, [f\"{t:.2f}*us\" for t in tau1_arr])\n",
    "# pg.add_dimension('wf_pz_dcr', 2, [f\"{t:.2f}*us\" for t in tau2_arr])\n",
    "# print('tau1:', tau1_arr)\n",
    "# print('tau2:', tau2_arr)\n",
    "\n",
    "rise_arr = np.linspace(6, 10, 5)\n",
    "flat_arr = np.linspace(15, 21, 10)\n",
    "print(rise_arr)\n",
    "print(flat_arr)\n",
    "\n",
    "pg.add_dimension('wf_dcr_trap', 1, [f\"{t:.2f}*us\" for t in rise_arr])\n",
    "pg.add_dimension('wf_dcr_trap', 2, [f\"{t:.2f}*us\" for t in flat_arr])\n",
    "\n",
    "ngrid = pg.get_n_grid_points()\n",
    "print('grid points to search:', ngrid)\n",
    "\n",
    "# the more waveforms we have, the longer it will take to run one grid point\n",
    "nwfs = tb_wfs[pk_select]['waveform']['values'].nda.shape[0]\n",
    "print('wfs to reprocess:', nwfs * ngrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6585b34-33e0-4941-92d4-7fcb1bccfb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the grid search.\n",
    "\n",
    "# NOTE: the fom_function does NOT support additional function arguments.\n",
    "fom_vals = run_grid(tb_wfs[pk_select], dsp_config, pg, mean_val, db_dict=dsp_db, verbosity=0)\n",
    "\n",
    "# unpack the results into a DataFrame.  \n",
    "# have to iterate thru the n-dimensional grid\n",
    "grid_nd = []\n",
    "ix = pg.get_zero_indices()\n",
    "while True:\n",
    "    row = []\n",
    "    for i_dim, i_par in enumerate(ix):\n",
    "        name, i_arg, value_str, _ = pg.get_data(i_dim, i_par)\n",
    "        row.append(value_str)\n",
    "    grid_nd.append(row)\n",
    "    if not pg.iterate_indices(ix): break\n",
    "\n",
    "df_grid = pd.DataFrame(grid_nd, columns=['rise','flat'])\n",
    "\n",
    "results_1d = fom_vals.reshape(-1, pg.get_n_grid_points())\n",
    "df_grid['fom'] = results_1d[0]\n",
    "\n",
    "print(\"NOTE: if one of the best settings is at the upper/lower limit of your parameter grid,\",\n",
    "      \"\\nyou probably need to adjust the grid to find the true min.\")\n",
    "\n",
    "# df_grid # show full df\n",
    "df_best = df_grid.sort_values('fom', key=abs)\n",
    "df_best[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efb3eb9-4b3c-4d08-8e2f-b7d21d11a748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the dsp_db with the best result.\n",
    "print(df_best.iloc[0])\n",
    "dbest = df_grid.sort_values('fom', key=abs).iloc[0].to_dict()\n",
    "\n",
    "dbest\n",
    "\n",
    "for par, val in dbest.items():\n",
    "    if par == 'fom': continue\n",
    "    dsp_db['dcr_trap'][par] = val\n",
    "    \n",
    "print(\"NOTE: you can go back and re-run the WaveformBrowser step now,\",\n",
    "     \"\\nto see the effect of the updated values.\")\n",
    "\n",
    "dsp_db\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6081d4d2-9bc3-49b2-a987-4466728deb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "# run dsp with the best result and check the central value of DCR\n",
    "\n",
    "print('DB parameters:')\n",
    "pprint(dsp_db)\n",
    "# pprint(dsp_config)\n",
    "\n",
    "# run dsp\n",
    "tb_out = run_one_dsp(tb_wfs[pk_select], dsp_config, db_dict=dsp_db, verbosity=1)\n",
    "\n",
    "# print(tb_out.keys())\n",
    "df = tb_out.get_dataframe()\n",
    "# print(df)\n",
    "\n",
    "# make a quick histogram of the dcr column.  pandas auto-histogram for a column should be enough\n",
    "df.hist('dcr', bins=int(len(df) * 0.1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7203ad0-4bae-4f2f-a766-62fd4e4e9369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load our skim waveforms file\n",
    "f_input = f_wfs \n",
    "tb_input = f'{tb_in}/{pk_select}'\n",
    "\n",
    "print('DB input parameters:')\n",
    "pprint(dsp_db)\n",
    "\n",
    "b = wfb(f_input, tb_input, dsp_config,\n",
    "        waveforms=['wf_blsub', 'wf_pz', 'wf_pz_dcr', 'wf_dcr_trap'],\n",
    "        database=dsp_db,\n",
    "        # legend=['wf_blsub', 'wf_pz', 'wf_etrap', 'wf_atrap'],\n",
    "        # lines=['tp_ftp', 'tp_0', 'trapEftp', 'tp_ftp'],\n",
    "        x_lim=(38000, 80000)\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037f323b-ace7-404c-9f8f-6cb266d4d07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "b.draw_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486c6808-c366-478a-9e6d-36bd7d351cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(dsp_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccb31e2-75bd-41e3-868a-9b969ff41f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: now you need to make the 2D plot with DCR vs Energy to see alpha/gamma separation.\n",
    "# it can take 3-4 minutes to process each file.  \n",
    "# to speed up the time it takes to search the parameter space, we apply a pretty aggressive low-e cut.\n",
    "# we can come back and process the full file at the end.\n",
    "\n",
    "%time\n",
    "nlim = 1\n",
    "files_in = raw_files[:nlim]\n",
    "\n",
    "# run dsp on the full file.  can take a while ... 2-3 mins\n",
    "print('DB parameters:')\n",
    "pprint(dsp_db)\n",
    "# pprint(dsp_config)\n",
    "\n",
    "# apply low-e cut\n",
    "# raw_data = pd.DataFrame(lh5.load_nda(raw_file, data_cols, tb_in, verbose=False))\n",
    "raw_e = lh5.load_nda(raw_files[:nlim], ['energy'], tb_in, verbose=False)\n",
    "\n",
    "print(type(raw_e['energy']))\n",
    "\n",
    "ix = np.where(raw_e['energy'] > 1e6)[0] # this is somewhere between 583 and 1460. \n",
    "print(type(ix))\n",
    "\n",
    "print(type(raw_files[:nlim]))\n",
    "\n",
    "# read the waveforms.  this can take quite a while (3--4 minutes)\n",
    "tb_data, n_wfs = sto.read_object(tb_in, raw_files[:nlim], idx=ix)\n",
    "print(n_wfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69faa81c-0d12-4686-bb3a-5ac7cc25a73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG line -- manually vary dsp_db\n",
    "\n",
    "# dsp_db['dcr_pz']['tau1'] = \"60*us\" # best: 52*us\n",
    "# dsp_db['dcr_pz']['tau2'] = \"6.4*us\" # best: 6.4*us\n",
    "# dsp_db['dcr_pz']['frac'] = \"0.043\" # best: 0.043\n",
    "# dsp_db['dcr_trap']['rise'] = \"8*us\"\n",
    "# dsp_db['dcr_trap']['flat']= \"23*us\"\n",
    "# dsp_db['dcr']['ftp'] = \"80*us\"\n",
    "\n",
    "# dcr_trap rise/flat maxes: [10, 20], [9, 22]\n",
    "\n",
    "# run the dsp\n",
    "tb_out = run_one_dsp(tb_data, dsp_config, db_dict=dsp_db, verbosity=0)\n",
    "print(tb_out.keys())\n",
    "df_data = tb_out.get_dataframe()\n",
    "# df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26ae05c-a1bf-4768-8259-050ebaac4aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "# 2D plot of DCR vs trapEftp\n",
    "\n",
    "xlo, xhi, xpb = 0, 15000, 10\n",
    "ylo, yhi, ypb = -200, 200, 1\n",
    "# ylo, yhi, ypb = -600, 0, 1\n",
    "\n",
    "nbx = int((xhi-xlo)/xpb)\n",
    "nby = int((yhi-ylo)/ypb)\n",
    "\n",
    "plt.hist2d(df_data.trapEftp, df_data.dcr, range=((xlo,xhi),(ylo,yhi)), bins=(nbx, nby), \n",
    "           cmap='jet', norm=LogNorm())\n",
    "\n",
    "plt.xlabel('trapEftp')\n",
    "plt.ylabel('dcr')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a05495b-7d5a-4edc-9d50-92157c12e274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally, write the DB to an output text file.\n",
    "\n",
    "pprint(dsp_db)\n",
    "\n",
    "# try writing to a temporary file\n",
    "f_dsp = './metadata/optimizer_results.json'\n",
    "with open(f_dsp, 'w') as f:\n",
    "    json.dump(dsp_db, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21441e00-3924-4471-bd23-7d0b83a53bbb",
   "metadata": {},
   "source": [
    "## 4. Charge Trapping Correction\n",
    "\n",
    "Two methods:\n",
    "* Drift Time\n",
    "* DCR\n",
    "    \n",
    "FIRST, you want to optimize the energy trapezoids & pole zero consts by themselves.  \n",
    "(That's what all the work up to this point was for!)\n",
    "THEN, you can improve the resolution further by introducing a corrected parameter.\n",
    "\n",
    "1. DT method:\n",
    "Fixed time pickoff should be the same as the ramp time, started at t0.  \n",
    "Second region must be totally in the flat top, first region starts at t0\n",
    "The correction should be: `E_new = E + const * qDrift`, but need to check it works for multiple peaks.\n",
    "It might also be `E_new = E * (1 + const * qDrift)`\n",
    "\n",
    "2. DCR method: \n",
    "DCR-modified E: `E_new = E + const * DCR`\n",
    "The reason this is as effective as the drift time method is that delayed charge collection from the **bulk** is released w. some time constant on the order of the digitizer window length.  This will make it show up in the tail of the waveforms.  Of course, alpha events have delayed collection from the **surface** as well, which should have a different time constant.\n",
    "\n",
    "In MJD, charges are significantly trapped but released before next event due to the lower operating temperature, 77 K.\n",
    "In the STCs and CAGE, the operating temp is closer to 85 or 90 K, and the charge re-release time will be faster. \n",
    "So we will have to decide for ourselves if Method 1 (DT) or Method 2 (DCR) is a more effective charge trapping correction for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4981998-8589-4bdc-b3a3-34e878398099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lol TBD  :-)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
