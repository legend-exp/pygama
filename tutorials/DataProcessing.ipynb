{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a18b7b84-6bbc-4e89-bcbf-d20e851ec520",
   "metadata": {},
   "source": [
    "# Data Processing and Access 101\n",
    "\n",
    "Ian Guinn, UNC. Presented at [LEGEND Software Tutorial, Nov. 2021](https://indico.legend-exp.org/event/561/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dab0cfd-4867-4836-b80a-d36f91d71909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up python environment\n",
    "from pygama.io.daq_to_raw import daq_to_raw\n",
    "from pygama.io.raw_to_dsp import raw_to_dsp\n",
    "from pygama.lh5.store import *\n",
    "\n",
    "daq_file = '/global/cfs/cdirs/m2676/data/legend-testdata/data/cage/2021-1-16-CAGERun1250'\n",
    "raw_file = \"metadata/CAGERun1250_raw.lh5\"\n",
    "dsp_file = \"metadata/CAGERun1250_dsp.lh5\"\n",
    "\n",
    "dsp_config = \"./metadata/dsp_config.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e2ba70-7278-439b-aacc-dfb470ae689a",
   "metadata": {},
   "source": [
    "## Running daq_to_raw\n",
    "\n",
    "Our first step in processing is to run daq_to_raw, which will decode the binary file produced by our DAQ system and output an HDF5 file following LEGEND's lh5 file specification. This requires us to provide an input file, an output file name, and a dictionary of settings. Because the CAGE file we are using comes from ORCA, the config is extremely simple; for other DAQ systems, this can get more complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1709baf9-87d6-41fe-8973-fdc851b75ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config would normally be provided as a JSON file\n",
    "d2r_config = {\n",
    "    'daq':'ORCA'\n",
    "}\n",
    "\n",
    "daq_to_raw(daq_file,\n",
    "           raw_file,\n",
    "           config=d2r_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8aa7e3d-8393-47f7-b0fc-0483648af5b0",
   "metadata": {},
   "source": [
    "## Inspecting the raw file\n",
    "\n",
    "Next, we'll look at the file output from daq_to_raw. The file is output using the LH5 specification, and can be accessed using the pygama.lh5.store module.\n",
    "\n",
    "First, we'll create a Store object, and call ls to list the contents of the hdf group containing our data. Then, we'll call load_dfs to create a pandas dataframe. Note that the pandas dataframe will not contain the waveforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b640db89-baf5-47c6-9b4e-e71ee0c48c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "lh5_st = Store()\n",
    "print(\"List of raw file elements:\")\n",
    "print(lh5_st.ls(raw_file, 'ORSIS3302DecoderForEnergy/raw/'))\n",
    "\n",
    "print()\n",
    "print(\"Data from file:\")\n",
    "raw_df = load_dfs(raw_file,\n",
    "                  par_list = ['card', 'channel', 'crate', 'energy', 'energy_first',\n",
    "                              'ievt', 'packet_id', 'timestamp'],\n",
    "                  lh5_group = 'ORSIS3302DecoderForEnergy/raw/')\n",
    "print(raw_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb2240b-f4c4-44f3-a252-8d5a0035b888",
   "metadata": {},
   "source": [
    "## Running raw_to_dsp\n",
    "\n",
    "The next stop in our processing is to run raw_to_dsp, which will run a sequence of digital signal processors and output the results into another lh5 file. These processors are set up using a dictionary which will be provided by a JSON file. For more details about how to set up this file, see other tutorials.\n",
    "\n",
    "Many processors benefit from having optimized parameters for each channel and run range. This optimization process is not covered by this tutorial, but the parameters are stored in a the metadata database, and is provided to raw_to_dsp using a json file or dict. In this example, we will provide the pole-zero correction time constant in this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f31981c-26ff-49ef-adc9-6a57b8dc6927",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_dict = {'ORSIS3302DecoderForEnergy': {\n",
    "    'pz': { 'tau':\"48*us\" }\n",
    "    }\n",
    "}\n",
    "\n",
    "raw_to_dsp(raw_file, dsp_file, dsp_config,\n",
    "           database = db_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53012d1c-d539-4ede-9170-2103823105af",
   "metadata": {},
   "source": [
    "## Inspecting the dsp file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06219ef8-ad9a-496b-a735-6e5f2de8ce04",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"List of raw file elements:\")\n",
    "print(lh5_st.ls(dsp_file, 'ORSIS3302DecoderForEnergy/dsp/'))\n",
    "\n",
    "print()\n",
    "print(\"Data from file:\")\n",
    "raw_df = load_dfs(dsp_file,\n",
    "                  par_list = ['trapEmax', 'bl_mean', 'timestamp', 'AoE'],\n",
    "                  lh5_group = 'ORSIS3302DecoderForEnergy/dsp/')\n",
    "print(raw_df)\n",
    "\n",
    "raw_df.hist('trapEmax', bins=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f59e52-73e4-4de4-8999-d2f5cba1da1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
