{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86849118-dec9-4972-a94e-297d5625ebba",
   "metadata": {},
   "source": [
    "<font size=\"1\">Tutorial by Danielle Schaper (based on original tutorial by Ian Guinn, UNC., which was presented at [LEGEND Software Tutorial, Nov. 2021](https://indico.legend-exp.org/event/561/) )</font>\n",
    "\n",
    "</font><font size=\"1\"> NOTE: This tutorial is made to use the newer (refactored) version of pygama, version 1.0. The tutorials presented at the Nov. 2021 workshop used the older version of pygama, version 0.9. At the time of writing this tutorial, the version of pygama used was version 1.0.2 (specifically, 1.1.1.dev5+geb536311)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267092cc-4d9c-4bb5-b5c8-97290677c4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygama\n",
    "print(pygama.__path__)\n",
    "print(pygama.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be406d8-e84b-4e04-aedd-f2b18eaa10c8",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# <font color ='green'>Data Processing and Access 101: Overview of this Tutorial</font>\n",
    "\n",
    "\n",
    "There are three main stages of data files in the LEGEND analysis process: ORCA files, \"raw\" files, and \"DSP\" files. Briefly:\n",
    "1) ORCA files: These are the files that come straight off of the FlashCam cards. They consist of an ORCA header, and then raw binary data.\n",
    "\n",
    "2) Raw files: After the ORCA files have undergone some basic processing in order to structure the binary data into HDF5-formatted files. These files contain run information and the raw (un-processed) waveforms.\n",
    "\n",
    "3) DSP files: These files have undergone more rigorous DSP (digital signal processing) routines and contain the processed waveforms as well as lists of input parameters that were used to process the raw waveforms (e.g. trap filter rise time) and lists of parameters which were extracted from these analysis routines (e.g. trapEmax).\n",
    "\n",
    "The primary goal of this tutorial is to walk the user through the stages of the ORCA ---> Raw ---> DSP conversions. In addition, we show how to inspect the contents of the files along the way by 1) Using the pygama WaveformBrowser functionality as well as 2) Structuring data into PANDAS dataframes and using the native PANDAS utilities to look at the data.\n",
    "\n",
    "The data files that will be used in this tutorial are contained in the legend-testdata repository. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fef86d-f25b-4fcd-ba38-12a688337369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up python environment. This tutorial assumes that the user is running the refactored version of pygama.\n",
    "import os,json, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from legend_testdata import LegendTestData\n",
    "\n",
    "# Pygama modules needed for this tutorial\n",
    "from pygama.raw  import build_raw\n",
    "from pygama.dsp  import build_dsp\n",
    "from pygama.lgdo import LH5Store as lh5_st\n",
    "from pygama.lgdo import ls # Needed to do this to access the ls function since it is not a method of the LH5Store class\n",
    "from pygama.lgdo import load_dfs\n",
    "from pygama.vis.waveform_browser import WaveformBrowser\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51f9142-cbd1-4d32-b535-ec291486dfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in data from legend-testdata and check to make sure the path can be found.\n",
    "ldata=LegendTestData()\n",
    "ldata.get_path(\"orca/fc/L200-comm-20220519-phy-geds.orca\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad15ed1-3888-41a2-8792-c3e19694927d",
   "metadata": {},
   "source": [
    "# Building a 'raw' file from a .orca DAQ file\n",
    "\n",
    "Our first step in processing is to run build_raw (found in the <font color ='orange'>pygama.raw module</font>), which will decode the binary file produced by our DAQ system and output an HDF5 file following LEGEND's lh5 file specification. This requires us to provide an input file, an output file name, and a dictionary of settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a363c7d7-de8a-475c-a121-9b6d4ffd4f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You will need to change the path 'orca_file' to point to the .orca file that you will want to analyze. Here, we will use one of the L-200 commissioning datafiles.\n",
    "\n",
    "# Load in the desired ORCA file from legend-testdata\n",
    "ldata=LegendTestData()\n",
    "ldata.get_path(\"orca/fc/L200-comm-20220519-phy-geds.orca\")\n",
    "orca_file = ldata.get_path(\"orca/fc/L200-comm-20220519-phy-geds.orca\")\n",
    "\n",
    "# These will be the output filenames for this tutorial\n",
    "raw_file = 'pygamaTutorialRAWfile.lh5'\n",
    "dsp_file = 'pygamaTutorialDSPfile.lh5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c1627c-e55f-43b9-9da6-1220429d8be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a generic configuration file that can be used in the build_raw() function. It is generic because it relies on wildcards to parse the input files.\n",
    "# The only specialized argument here is the out_stream argument so that it returns a file specifically named 'pygamaTutorialRAW.lh5'\n",
    "# This config file template can be found in the legend-exp/legend-dataflow/scripts/build_raw.py GitHub repository\n",
    "\n",
    "out_spec = { \n",
    "\"ORFlashCamADCWaveformDecoder\" : {\n",
    "  \"ch{key:03d}/raw\" : {\n",
    "  \"key_list\" : [\"*\"],\n",
    "  \"out_stream\" : \"pygamaTutorialRAWfile.lh5\"\n",
    "  }\n",
    " }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e17fe15-4d04-4168-ac57-038482624074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change overwrite = TRUE to allow the system to overwrite the existing file. This is useful if you are making small tweaks in this tutorial and then re-running the cell multiple times.\n",
    "overwrite_raw = True\n",
    "\n",
    "# Build the raw file\n",
    "build_raw(orca_file, in_stream_type='ORCA',\n",
    "         out_spec=out_spec, overwrite = overwrite_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12071519-56b3-488b-8d7b-04d7b8f70f28",
   "metadata": {},
   "source": [
    "## Inspecting the raw file\n",
    "\n",
    "Next, we'll look at the file output from daq_to_raw. The file is output using the LH5 specification, and can be accessed using the lh5_st() function in the <font color ='orange'>pygama.lgdo.LH5Store</font> module.\n",
    "\n",
    "First, we'll create a Store object, and call ls to list the contents of the hdf5 group containing our data. Then, we'll call load_dfs to create a pandas dataframe. Note that the pandas dataframe will not contain the waveforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ef0028-dd85-406f-84ca-224b47518e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_object = lh5_st()\n",
    "print(\"List of raw file elements:\")\n",
    "print(ls(raw_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d7581b-f7e0-42c9-8c52-290b095e5922",
   "metadata": {},
   "source": [
    "## Using the Waveform Browser to peek at a raw waveform\n",
    "\n",
    "This is done using the WaveformBrowser function in the <font color ='orange'>pygama.vis.waveform_browser</font> module. Here we "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935a1c56-b0b8-4b85-a4c9-4d7bd724332c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this tutorial, we will look at channel ch000\n",
    "\n",
    "channel = 'ch000'\n",
    "browser1 = WaveformBrowser(raw_file, lh5_group = channel +\"/raw\", lines = \"waveform\")\n",
    "browser2 = WaveformBrowser(raw_file, lh5_group = channel +\"/raw\", lines = \"waveform\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75b2ca9-7e19-46f2-8d09-d77780b17689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the first waveform in the file\n",
    "browser1.draw_entry(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc72017-634e-4fb8-ae1d-cfbd831de990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To browse through the waveforms in the file, you can use the draw_next() function. Re-running this cell will update the plot.\n",
    "fig = browser1.new_figure()\n",
    "fig = browser1.draw_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f887412-867e-4053-a5de-e4929ea9de9d",
   "metadata": {},
   "source": [
    "## Structuring Data into PANDAS DataFrame\n",
    "\n",
    "Let's pick a few parameters/values that we might be interested in and put them into a PANDAS dataframe so that we can look through them more easily. We can do this using the load_dfs() function found in the <font color ='orange'>pygama.lgdo</font> module. In order to do this (so that you know what inputs to use for the par_list and the lh5_group arguments), one must first know the HDF5 structure of the raw file. If you need help with this, please see the \"UnderstandingHDF5Files\" tutorial.\n",
    "\n",
    "Here we are choosing to import a subset of the data contained in the raw file into a dataframe. We are interested in the *card, channel, crate, daqenergy, packet_id*, and *timestamp* datasets, which can all be found in the ORFlashCamADCWaveform HDF5 group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d234f8f5-ed57-45ef-ad0a-768d6cdb864b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = load_dfs(raw_file, par_list = ['card', 'channel', 'crate', 'daqenergy',\n",
    "                              'packet_id', 'timestamp'], lh5_group = channel + '/raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe2d480-f7d4-4ec0-a95b-89166408e874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can inspect the contents of the dataframe and see if they make sense. You can play with changing the channel number and seeing how the dataframe updates.\n",
    "print(raw_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff44f24-5584-4e95-8ce8-2529be17400f",
   "metadata": {},
   "source": [
    "## Building the DSP file from the Raw file\n",
    "\n",
    "In order to convert the raw data file into one that has been processed using DSP routines, we will need two input files:\n",
    "\n",
    "1) A **global** configuration file which contains the information about the DSP processes that we wish to run on the data. Ideally, this configuration file remains static for all of the analyses that will be done across different datasets. This configuration file is defined in this tutorial as **dsp_config**.\n",
    "\n",
    "2) A **local** configuration file which contains channel-specific (i.e. detector-specific) information and parameters. This configuration file will change between datasets, as its purpose is to perform minor corrections/adjustments to the data processes which originate from detector-specific fluctuations. This configuration file is defined in this tutorial as **db_dict**.\n",
    "\n",
    "Example dsp_config and db_dict files have been included explicitly in this tutorial directory so as to minimize needing to import external files and to ensure the same files are used. These files can be found in the ./metadata directory. For more information on how these files affect the data and how to modify/manipulate them, please see the WriteProcessors and the IntroToDSP tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b020e22-705e-468d-8403-5c71498e4ed9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We will use the dsp-config file in the ./metadata directory. If you'd like to see the file contents of the db_dict JSON file, you can uncomment and run this cell to print them.\n",
    "\n",
    "## Uncomment this block to see the dsp-config file contents\n",
    "#dsp_config_file_path = \"./metadata/dsp-config-dataprocessing.json\"\n",
    "#with open(dsp_config_file_path, 'r') as j:\n",
    "#     contents = json.loads(j.read())\n",
    "#print(json.dumps(contents, indent=2))\n",
    "\n",
    "## Uncomment this block to see the db_dict file contents\n",
    "#db_dict_file_path = \"./metadata/db_dict.json\"\n",
    "#with open(db_dict_file_path, 'r') as j:\n",
    "#     contents = json.loads(j.read())\n",
    "#print(json.dumps(contents, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6d932c-191e-48ff-995b-9f8595a5d77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the necessary dsp_config and db_dict JSON files.\n",
    "dsp_config = \"./metadata/dsp-config-dataprocessing.json\"\n",
    "db_dict = \"./metadata/db_dict.json\"\n",
    "\n",
    "# Build the DSP file\n",
    "build_dsp(raw_file, dsp_file, dsp_config = dsp_config, database = db_dict, write_mode = 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249053d9-d34e-4999-81e1-f09e40110a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsp_df=load_dfs(dsp_file, par_list=['trapEmax'], lh5_group=channel +'/dsp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27717c0-1d8b-4623-a85f-a2f77c6e65b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dsp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a067c6b7-666b-4b83-bf93-40e7bc47b07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the results of the trapEmax filter; there are only 12 events in this test data file, so the spectrum is of course not that impressive. It just matters that it works.\n",
    "dsp_df.hist('trapEmax',bins=50)\n",
    "plt.xlabel(\"Energy [keV]\")\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.ylim(0,10)\n",
    "plt.xlim(0,20900)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3678ba40-2ccd-4af1-935c-2b1f5d6fa3ba",
   "metadata": {},
   "source": [
    "# Inspecting the DSP File Using the Waveform Browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e1a96b-bb0d-4117-b52c-c7f561511107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an LH5 Store object\n",
    "DSP_Store =lh5_st()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1174bcd0-25cd-4e0a-b2e2-fdd455ed2f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the contents of the DSP file for a given channel\n",
    "channel = 'ch000'\n",
    "ls('pygamaTutorialDSPfile.lh5', channel + '/dsp/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bc1a60-d2e8-469b-b887-3cb6f590bce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see that we processed the waveforms, we shall plot the baseline-subtracted waveform, 'wf_blsub.'\n",
    "browser_dsp = WaveformBrowser(dsp_file, lines='wf_blsub', lh5_group= channel + \"/dsp\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0515acc1-b77b-4951-af35-f20758be34fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the 1st waveform in the file -- it should look like the waveform that we drew earlier from the raw file, just adjusted to a zero baseline.\n",
    "browser_dsp.draw_entry(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26167e2-6880-4fcc-ac83-9ea8e07794af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To browse through the waveforms in the file, you can use the draw_next() function. Re-running this cell will update the plot.\n",
    "fig = browser_dsp.new_figure()\n",
    "fig = browser_dsp.draw_next()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
